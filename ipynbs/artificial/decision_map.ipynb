{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = os.path.join('/home/htc/kchitranshi', 'learning-from-adversarial-perturbations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting pytorch-lightning==1.8.6\n",
      "  Using cached pytorch_lightning-1.8.6-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting lightning-lite\n",
      "  Using cached lightning_lite-1.8.6-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy>=1.17.2 (from pytorch-lightning==1.8.6)\n",
      "  Using cached numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (6.0.2)\n",
      "Collecting fsspec>2021.06.0 (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tensorboardX>=2.2 (from pytorch-lightning==1.8.6)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.8.6)\n",
      "  Using cached torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (4.12.2)\n",
      "Collecting lightning-utilities!=0.4.0,>=0.3.0 (from pytorch-lightning==1.8.6)\n",
      "  Using cached lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.55.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached aiohttp-3.11.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities!=0.4.0,>=0.3.0->pytorch-lightning==1.8.6) (75.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting protobuf>=3.20 (from tensorboardX>=2.2->pytorch-lightning==1.8.6)\n",
      "  Using cached protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6) (3.10)\n",
      "Using cached pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached lightning_lite-1.8.6-py3-none-any.whl (136 kB)\n",
      "Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "Using cached matplotlib-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.55.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Using cached lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Using cached numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "Using cached pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached aiohttp-3.11.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Installing collected packages: mpmath, tzdata, threadpoolctl, sympy, pyparsing, protobuf, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, lightning-utilities, kiwisolver, joblib, fsspec, frozenlist, fonttools, filelock, cycler, aiohappyeyeballs, yarl, triton, tensorboardX, scipy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, contourpy, aiosignal, scikit-learn, nvidia-cusolver-cu12, matplotlib, aiohttp, torch, seaborn, torchvision, torchmetrics, lightning-lite, pytorch-lightning\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.9 aiosignal-1.3.1 contourpy-1.3.1 cycler-0.12.1 filelock-3.16.1 fonttools-4.55.1 frozenlist-1.5.0 fsspec-2024.10.0 joblib-1.4.2 kiwisolver-1.4.7 lightning-lite-1.8.6 lightning-utilities-0.11.9 matplotlib-3.9.3 mpmath-1.3.0 multidict-6.1.0 networkx-3.4.2 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 pillow-11.0.0 propcache-0.2.1 protobuf-5.29.0 pyparsing-3.2.0 pytorch-lightning-1.8.6 scikit-learn-1.5.2 scipy-1.14.1 seaborn-0.13.2 sympy-1.13.1 tensorboardX-2.6.2.2 threadpoolctl-3.5.0 torch-2.5.1 torchmetrics-1.6.0 torchvision-0.20.1 triton-3.1.0 tzdata-2024.2 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import dataclasses\n",
    "import os\n",
    "from typing import Any, Dict, Literal, Optional, Tuple\n",
    "%pip install pandas torch pytorch-lightning==1.8.6 lightning-lite torchvision scikit-learn matplotlib seaborn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from utils.classifiers import OneHiddenNet\n",
    "from utils.decision_map import (get_axis_vec, get_decision_map,\n",
    "                                get_inputs_for_decision_map)\n",
    "from utils.fig import Figure\n",
    "from utils.utils import freeze, gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "Figure.set_seaborn_theme()\n",
    "Figure.set_high_dpi()\n",
    "device = gpu(0)\n",
    "resolution = 800\n",
    "limit = 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class DataUtil:\n",
    "    in_dim: int\n",
    "    hidden_dim: int\n",
    "    n_sample: int\n",
    "    n_noise_sample: int\n",
    "    n_noise_samples: Tuple[int, ...]\n",
    "    norm: Literal['L0', 'L2', 'Linf']\n",
    "    mode: Literal['uniform', 'gauss']\n",
    "    perturbation_constraint: float\n",
    "    seed: int\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.d = self._load_data()\n",
    "    \n",
    "    def _load_data(self, n_noise_sample: Optional[int] = None) -> Dict[str, Any]:\n",
    "        n_noise_sample = n_noise_sample if n_noise_sample else self.n_noise_sample\n",
    "        fname = f'{self.in_dim}_{self.hidden_dim}_{self.n_sample}_{n_noise_sample}' + \\\n",
    "                f'_{self.norm}_{self.mode}_{self.perturbation_constraint}_{self.seed}'\n",
    "        path = os.path.join('/home/htc/kchitranshi/SCRATCH/', 'artificial', fname)\n",
    "        return torch.load(path, map_location='cpu')\n",
    "    \n",
    "    def _define_classifier(self) -> OneHiddenNet:\n",
    "        classifier = OneHiddenNet(self.in_dim, self.hidden_dim)\n",
    "        classifier.to(device)\n",
    "\n",
    "        freeze(classifier)\n",
    "        classifier.eval()\n",
    "        \n",
    "        return classifier\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_boundary(\n",
    "        self, \n",
    "        classifier: OneHiddenNet, \n",
    "        inputs_for_decision_map: Tensor,\n",
    "        weight_key: Literal['classifier', 'adv_classifier'],\n",
    "        n_noise_sample: Optional[int] = None,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        d = self._load_data(n_noise_sample)\n",
    "        classifier.load_state_dict(d[weight_key])\n",
    "\n",
    "        map = get_decision_map(classifier, inputs_for_decision_map)\n",
    "        \n",
    "        x_indices = map.argmax(1)\n",
    "        y = torch.linspace(-limit, limit, resolution)\n",
    "        x = y[x_indices].flip(0)\n",
    "\n",
    "        # upsampling\n",
    "        r = torch.linspace(-limit, limit, 10000)\n",
    "        y = y[resolution//2] + (y[-10] - y[0]) / (x[-10] - x[0]) * r\n",
    "\n",
    "        return r, y\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _project_natural_input(self, axis_vec_1: Tensor, axis_vec_2: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        natural_input = self.d['data']\n",
    "        s = natural_input.shape\n",
    "        x = (natural_input * axis_vec_1).expand(s).sum(1)\n",
    "        y = (natural_input * axis_vec_2).expand(s).sum(1)\n",
    "        return x, y\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def calc(self) -> Any:\n",
    "        results = []\n",
    "\n",
    "        classifier = self._define_classifier()\n",
    "\n",
    "        axis_vec_1, axis_vec_2 = get_axis_vec(self.d['classifier']['linear.weight'])\n",
    "        \n",
    "        inputs_for_decision_map = get_inputs_for_decision_map(axis_vec_1, axis_vec_2, resolution, limit)\n",
    "        inputs_for_decision_map = inputs_for_decision_map.to(device)\n",
    "\n",
    "        # standard boundary\n",
    "        std_x, std_y = self._get_boundary(classifier, inputs_for_decision_map, 'classifier')\n",
    "        results.append([std_x, std_y])\n",
    "\n",
    "        # perturbation learning boundary\n",
    "        for n_noise_sample in self.n_noise_samples:\n",
    "            adv_x, adv_y = self._get_boundary(classifier, inputs_for_decision_map, 'adv_classifier', n_noise_sample)\n",
    "            results.append([adv_x, adv_y])\n",
    "            \n",
    "        # scatter\n",
    "        s_x, s_y = self._project_natural_input(axis_vec_1, axis_vec_2)\n",
    "        indices = self.d['labels'] == 1\n",
    "        results.append([s_x[indices], s_y[indices]])\n",
    "        results.append([s_x[~indices], s_y[~indices]])\n",
    "\n",
    "        # Noise map\n",
    "        classifier.load_state_dict(self.d['noise_classifier'])\n",
    "        map = get_decision_map(classifier, inputs_for_decision_map)\n",
    "        results.append(map)\n",
    "\n",
    "        return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134/3320494345.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "in_dim = 10000\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_noise_sample = 100\n",
    "n_noise_samples = (10, 20, 100)\n",
    "norm = 'L2'\n",
    "mode = 'uniform'\n",
    "perturbation_constraint = 0.78\n",
    "seed = 5\n",
    "\n",
    "data_utils = DataUtil(\n",
    "    in_dim,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    seed,\n",
    ")\n",
    "\n",
    "results = data_utils.calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Figure' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mFigure\u001b[49m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      2\u001b[0m ax \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mremove_xticks()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Figure' is not defined"
     ]
    }
   ],
   "source": [
    "f = Figure(1, 1, (3, 3))\n",
    "ax = f.axes[0][0]\n",
    "\n",
    "ax.remove_xticks()\n",
    "ax.remove_yticks()\n",
    "ax.set_xlim(-limit, limit)\n",
    "ax.set_ylim(-limit, limit)\n",
    "\n",
    "std_x, std_y = results[0]\n",
    "ax.ax.plot(std_x, std_y, color=Figure.light_palette[0], linewidth=1.5, antialiased=False, label='Standard')\n",
    "\n",
    "map: Tensor = results[6]\n",
    "y_indices = map.argmax(0)\n",
    "r = torch.linspace(limit, -limit, resolution)\n",
    "y = r[y_indices]\n",
    "\n",
    "r = torch.linspace(-limit, limit, resolution)\n",
    "x = torch.linspace(-limit, limit, 10000)\n",
    "\n",
    "y1 = (y[resolution//2 - 10] - y[0]) / (r[resolution//2 - 10] - r[0]) * torch.linspace(-limit, 0, 5000)\n",
    "y2 = (y[-10] - y[resolution//2+10]) / (r[-10] - r[resolution//2+10]) * torch.linspace(0, limit, 5000)\n",
    "y = torch.cat([y1, y2])\n",
    "\n",
    "ax.ax.plot(x, y, color=Figure.palette[1], linewidth=1.5, label='Noise')\n",
    "\n",
    "for (x, y), n_noise_sample, c, linestyle in zip(results[1:4], n_noise_samples, ('b', 'g', 'r'), ['dashdot', 'dashed', 'dotted']):\n",
    "    label = r'$N^\\mathrm{adv}=' + f'{n_noise_sample}$'\n",
    "    ax.ax.plot(x, y, color=c, linestyle=linestyle, linewidth=1.5, antialiased=False, label=label)\n",
    "\n",
    "s_x, s_y = results[4]\n",
    "ax.ax.scatter(\n",
    "    s_x, s_y, label='Positive',\n",
    "    s=80, alpha=0.35, linewidths=0.5, \n",
    "    edgecolors=Figure.dark_palette[0], c=[Figure.palette[0]], marker='o', # type: ignore\n",
    ")\n",
    "\n",
    "s_x, s_y = results[5]\n",
    "ax.ax.scatter(\n",
    "    s_x, s_y, label='Negative',\n",
    "    s=100, alpha=0.35, linewidths=0.5, \n",
    "    edgecolors=Figure.dark_palette[1], c=[Figure.palette[1]], marker='X', # type: ignore\n",
    ")\n",
    "\n",
    "ax.horizontal_quiver(limit)\n",
    "ax.vertical_quiver(limit)\n",
    "\n",
    "ax.ax.text(limit-0.25, 0.2, r'$\\bm{v}$', fontsize=12)\n",
    "ax.ax.text(0.2, limit-0.25, r'$\\bm{u}$', fontsize=12)\n",
    "\n",
    "f.fig.legend(loc='lower left', bbox_to_anchor=(-0.32, 0.344), ncols=1, frameon=True, fontsize=13, markerscale=0.6)\n",
    "\n",
    "f.save(root, 'figs', 'decision_map.pdf')\n",
    "f.show()\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
