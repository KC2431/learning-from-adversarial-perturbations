{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = os.path.join('/home/htc/kchitranshi', 'learning-from-adversarial-perturbations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting patchworklib\n",
      "  Using cached patchworklib-0.6.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting matplotlib>=3.4 (from patchworklib)\n",
      "  Using cached matplotlib-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas>=0.24 (from patchworklib)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy<1.27,>=1.16 (from patchworklib)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting dill (from patchworklib)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting seaborn (from patchworklib)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting plotnine<=0.13.6 (from patchworklib)\n",
      "  Using cached plotnine-0.13.6-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.4->patchworklib)\n",
      "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.4->patchworklib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.4->patchworklib)\n",
      "  Using cached fonttools-4.55.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.4->patchworklib)\n",
      "  Using cached kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->patchworklib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib>=3.4->patchworklib)\n",
      "  Using cached pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.4->patchworklib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->patchworklib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.24->patchworklib) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas>=0.24->patchworklib)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mizani~=0.11.0 (from plotnine<=0.13.6->patchworklib)\n",
      "  Using cached mizani-0.11.4-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting scipy>=1.7.0 (from plotnine<=0.13.6->patchworklib)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting statsmodels>=0.14.0 (from plotnine<=0.13.6->patchworklib)\n",
      "  Using cached statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->patchworklib) (1.16.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.14.0->plotnine<=0.13.6->patchworklib)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Using cached patchworklib-0.6.5-py3-none-any.whl (49 kB)\n",
      "Using cached matplotlib-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached plotnine-0.13.6-py3-none-any.whl (1.3 MB)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.55.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Using cached mizani-0.11.4-py3-none-any.whl (127 kB)\n",
      "Using cached pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "Using cached statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: tzdata, pyparsing, pillow, numpy, kiwisolver, fonttools, dill, cycler, scipy, patsy, pandas, contourpy, statsmodels, mizani, matplotlib, seaborn, plotnine, patchworklib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 dill-0.3.9 fonttools-4.55.1 kiwisolver-1.4.7 matplotlib-3.9.3 mizani-0.11.4 numpy-1.26.4 pandas-2.2.3 patchworklib-0.6.5 patsy-1.0.1 pillow-11.0.0 plotnine-0.13.6 pyparsing-3.2.0 scipy-1.14.1 seaborn-0.13.2 statsmodels-0.14.4 tzdata-2024.2\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting pytorch-lightning==1.8.6\n",
      "  Using cached pytorch_lightning-1.8.6-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting lightning-lite\n",
      "  Using cached lightning_lite-1.8.6-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.9.3)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (6.0.2)\n",
      "Collecting fsspec>2021.06.0 (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tensorboardX>=2.2 (from pytorch-lightning==1.8.6)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.8.6)\n",
      "  Using cached torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning==1.8.6) (4.12.2)\n",
      "Collecting lightning-utilities!=0.4.0,>=0.3.0 (from pytorch-lightning==1.8.6)\n",
      "  Using cached lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached aiohttp-3.11.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities!=0.4.0,>=0.3.0->pytorch-lightning==1.8.6) (75.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting protobuf>=3.20 (from tensorboardX>=2.2->pytorch-lightning==1.8.6)\n",
      "  Using cached protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6) (3.10)\n",
      "Using cached pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached lightning_lite-1.8.6-py3-none-any.whl (136 kB)\n",
      "Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached aiohttp-3.11.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, protobuf, propcache, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, multidict, lightning-utilities, joblib, fsspec, frozenlist, filelock, aiohappyeyeballs, yarl, triton, tensorboardX, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, aiosignal, nvidia-cusolver-cu12, aiohttp, torch, torchvision, torchmetrics, lightning-lite, pytorch-lightning\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.9 aiosignal-1.3.1 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.10.0 joblib-1.4.2 lightning-lite-1.8.6 lightning-utilities-0.11.9 mpmath-1.3.0 multidict-6.1.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 propcache-0.2.1 protobuf-5.29.0 pytorch-lightning-1.8.6 scikit-learn-1.5.2 sympy-1.13.1 tensorboardX-2.6.2.2 threadpoolctl-3.5.0 torch-2.5.1 torchmetrics-1.6.0 torchvision-0.20.1 triton-3.1.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install patchworklib\n",
    "import dataclasses\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Dict, List, Literal, Optional, Tuple\n",
    "!pip install numpy==1.26.4\n",
    "import matplotlib.pyplot as plt\n",
    "import patchworklib as pw\n",
    "%pip install pandas torch pytorch-lightning==1.8.6 lightning-lite torchvision scikit-learn matplotlib seaborn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "from utils.classifiers import OneHiddenNet\n",
    "from utils.decision_map import (get_axis_vec, get_decision_map,\n",
    "                                get_inputs_for_decision_map)\n",
    "from utils.fig import Axes, Figure\n",
    "from utils.utils import freeze, gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Setting & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Figure.set_high_dpi()\n",
    "device = gpu(0)\n",
    "resolution = 500\n",
    "limit = 3.4\n",
    "ylabels = ('Standard', 'Adversarial', 'Noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure.set_font_scale(1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class DataUtil:\n",
    "    in_dim: int\n",
    "    hidden_dim: int\n",
    "    n_sample: int\n",
    "    n_noise_sample: int\n",
    "    norm: Literal['L0', 'L2', 'Linf']\n",
    "    mode: Literal['uniform', 'gauss']\n",
    "    perturbation_constraint: float\n",
    "    seed: int\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.d = self._load_data()\n",
    "\n",
    "    def _load_data(self) -> Dict[str, Any]:\n",
    "        fname = f'{self.in_dim}_{self.hidden_dim}_{self.n_sample}_{self.n_noise_sample}' + \\\n",
    "                f'_{self.norm}_{self.mode}_{self.perturbation_constraint}_{self.seed}'\n",
    "        path = os.path.join('/home/htc/kchitranshi/SCRATCH', 'artificial', fname)\n",
    "        return torch.load(path, map_location='cpu')\n",
    "    \n",
    "    def _define_classifier(self) -> OneHiddenNet:\n",
    "        classifier = OneHiddenNet(self.in_dim, self.hidden_dim)\n",
    "        classifier.to(device)\n",
    "\n",
    "        freeze(classifier)\n",
    "        classifier.eval()\n",
    "        \n",
    "        return classifier\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_decision_maps_and_acc_list(self) -> Tuple[Tensor, Tensor]:\n",
    "        axis_vec_1, axis_vec_2 = get_axis_vec(self.d['classifier']['linear.weight'])\n",
    "        inputs = get_inputs_for_decision_map(axis_vec_1, axis_vec_2, resolution, limit)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        classifier = self._define_classifier()\n",
    "\n",
    "        decision_maps = torch.empty(3, resolution, resolution)\n",
    "        acc_list = torch.empty(3)\n",
    "\n",
    "        weight_keys = ('classifier', 'adv_classifier', 'noise_classifier')\n",
    "        acc_keys = ('acc', 'adv_acc_for_natural', 'noise_acc_for_natural')\n",
    "\n",
    "        for i, (weight_key, acc_key) in enumerate(zip(weight_keys, acc_keys)):\n",
    "            classifier.load_state_dict(self.d[weight_key])\n",
    "            decision_maps[i] = get_decision_map(classifier, inputs)\n",
    "            acc_list[i] = self.d[acc_key]\n",
    "\n",
    "        return decision_maps, acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(ABC):\n",
    "    suptitle: str\n",
    "    ylabels: Optional[Tuple[str, str, str]]\n",
    "    variables: Any\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.titles = self.variables\n",
    "\n",
    "    def _embed_decision_map_into_brick(\n",
    "        self,\n",
    "        brick: pw.Brick, \n",
    "        decision_map: Tensor, \n",
    "        acc: float, \n",
    "        title: Optional[float] = None, \n",
    "        ylabel: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        ax = Axes(brick)\n",
    "        ax.imshow(decision_map, True)\n",
    "        ax.set_xlabel( f'{int(100*acc)}' + r'\\%' )\n",
    "        if title is not None:\n",
    "            ax.set_title(f'{title:,}')\n",
    "        if ylabel is not None:\n",
    "            ax.set_ylabel(ylabel)\n",
    "\n",
    "    def _construct_block(\n",
    "        self,\n",
    "        decision_map_2dlist: Tensor,\n",
    "        acc_2dlist: Tensor, \n",
    "        suptitle: str,\n",
    "        titles: Tuple[float, float, float, float], \n",
    "        ylabels: Optional[Tuple[str, str, str]],\n",
    "    ) -> pw.Bricks:\n",
    "        \n",
    "        row_bricks_list: List[pw.Bricks] = []\n",
    "        for i, (decision_map_list, acc_list) in enumerate(zip(decision_map_2dlist, acc_2dlist)):\n",
    "\n",
    "            col_brick_list: List[pw.Brick] = []\n",
    "            for j, (decision_map, acc) in enumerate(zip(decision_map_list, acc_list)):\n",
    "\n",
    "                brick = pw.Brick()\n",
    "                col_brick_list.append(brick)\n",
    "                \n",
    "                title = titles[j] if i == 0 else None\n",
    "                ylabel = ylabels[i] if j == 0 and ylabels is not None else None\n",
    "\n",
    "                self._embed_decision_map_into_brick(brick, decision_map, acc.item(), title, ylabel)\n",
    "\n",
    "            row_bricks = pw.stack(col_brick_list, 0.05, '|')\n",
    "            row_bricks_list.append(row_bricks)\n",
    "\n",
    "        bricks: pw.Bricks = pw.stack(row_bricks_list, 0.05, '/')\n",
    "        bricks.set_suptitle(suptitle)\n",
    "        return bricks\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _define_artificial_instance(self, var: Any) -> DataUtil:\n",
    "        pass\n",
    "    \n",
    "    def __call__(self) -> pw.Bricks:\n",
    "        decision_map_block = torch.empty(3, 4, resolution, resolution)\n",
    "        acc_block = torch.empty(3, 4)\n",
    "\n",
    "        for i, var in enumerate(self.variables):\n",
    "            n = self._define_artificial_instance(var)\n",
    "            decision_maps, acc_list = n.get_decision_maps_and_acc_list()\n",
    "            decision_map_block[:, i] = decision_maps\n",
    "            acc_block[:, i] = acc_list\n",
    "\n",
    "        return self._construct_block(decision_map_block, acc_block, self.suptitle, self.titles, self.ylabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dimension Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class InputDimensionBlock(Block):\n",
    "    in_dims: Tuple[int, int, int, int]\n",
    "    hidden_dim: int\n",
    "    n_sample: int\n",
    "    n_noise_sample: int\n",
    "    norm: Literal['L2', 'Linf']\n",
    "    mode: Literal['uniform', 'gauss']\n",
    "    perturbation_constraints: Tuple[float, float, float, float]\n",
    "    seed: int\n",
    "    ylabels: Optional[Tuple[str, str, str]] = None\n",
    "    suptitle: str = r'Input dimension $d$'\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.variables = [(i, j) for i, j in zip(self.in_dims, self.perturbation_constraints)]\n",
    "        self.titles = self.in_dims\n",
    "\n",
    "    def _define_artificial_instance(self, var: Tuple[int, float]) -> DataUtil:\n",
    "        return DataUtil(var[0], self.hidden_dim, self.n_sample, self.n_noise_sample, \n",
    "                        self.norm, self.mode, var[1], self.seed)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Sample Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class NaturalSampleBlock(Block):\n",
    "    in_dim: int\n",
    "    hidden_dim: int\n",
    "    n_samples: Tuple[int, int, int, int]\n",
    "    n_noise_sample: int\n",
    "    norm: Literal['L2', 'Linf']\n",
    "    mode: Literal['uniform', 'gauss']\n",
    "    perturbation_constraint: float\n",
    "    seed: int\n",
    "    ylabels: Optional[Tuple[str, str, str]] = None\n",
    "    suptitle: str = r'Natural sample $N$'\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.variables = self.n_samples\n",
    "        super().__post_init__()\n",
    "\n",
    "    def _define_artificial_instance(self, var: int) -> DataUtil:\n",
    "        return DataUtil(self.in_dim, self.hidden_dim, var, self.n_noise_sample, \n",
    "                        self.norm, self.mode, self.perturbation_constraint, self.seed)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Sample Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class NoiseSampleBlock(Block):\n",
    "    in_dim: int\n",
    "    hidden_dim: int\n",
    "    n_sample: int\n",
    "    n_noise_samples: Tuple[int, int, int, int]\n",
    "    norm: Literal['L2', 'Linf']\n",
    "    mode: Literal['uniform', 'gauss']\n",
    "    perturbation_constraint: float\n",
    "    seed: int\n",
    "    ylabels: Optional[Tuple[str, str, str]] = None\n",
    "    suptitle: str = r'(Adversarial) noise sample $N^{\\mathrm{adv}}$'\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.variables = self.n_noise_samples\n",
    "        super().__post_init__()\n",
    "\n",
    "    def _define_artificial_instance(self, var: int) -> DataUtil:\n",
    "        return DataUtil(self.in_dim, self.hidden_dim, self.n_sample, var, \n",
    "                        self.norm, self.mode, self.perturbation_constraint, self.seed)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation Constraint Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class PerturbationConstraintBlock(Block):\n",
    "    in_dim: int\n",
    "    hidden_dim: int\n",
    "    n_sample: int\n",
    "    n_noise_samples: int\n",
    "    norm: Literal['L2', 'Linf']\n",
    "    mode: Literal['uniform', 'gauss']\n",
    "    perturbation_constraints: Tuple[float, float, float, float]\n",
    "    seed: int\n",
    "    ylabels: Optional[Tuple[str, str, str]] = None\n",
    "    suptitle: Optional[str] = None\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if self.suptitle is None:\n",
    "            if self.norm in ['L2', 'Linf']:\n",
    "                self.suptitle = r'Perturbation constraint $\\epsilon$'\n",
    "            else:\n",
    "                self.suptitle = r'Modified pixel ratio $d_\\delta/d$'\n",
    "        self.variables = self.perturbation_constraints\n",
    "        super().__post_init__()\n",
    "\n",
    "    def _define_artificial_instance(self, var: int) -> DataUtil:\n",
    "        return DataUtil(self.in_dim, self.hidden_dim, self.n_sample, self.n_noise_samples, \n",
    "                        self.norm, self.mode, var, self.seed)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_blocks(\n",
    "    in_dim: int,\n",
    "    in_dims: Tuple[int, int, int, int],\n",
    "    perturbation_constraints_along_with_in_dims: Tuple[float, float, float, float],\n",
    "    hidden_dim: int,\n",
    "    n_sample: int,\n",
    "    n_samples: Tuple[int, int, int, int],\n",
    "    n_noise_sample: int,\n",
    "    n_noise_samples: Tuple[int, int, int, int],\n",
    "    norm: Literal['L2', 'Linf'],\n",
    "    mode: Literal['uniform', 'gauss'],\n",
    "    perturbation_constraint: float,\n",
    "    perturbation_constraints: Tuple[float, float, float, float],\n",
    "    seed: int,\n",
    ") -> None:\n",
    "    in_dim_block = InputDimensionBlock(in_dims, hidden_dim, n_sample, n_noise_sample, \n",
    "                                       norm, mode, perturbation_constraints_along_with_in_dims, seed, ylabels)()\n",
    "    noise_sample_block = NoiseSampleBlock(in_dim, hidden_dim, n_sample, n_noise_samples, \n",
    "                                          norm, mode, perturbation_constraint, seed)()\n",
    "    natural_sample_block = NaturalSampleBlock(in_dim, hidden_dim, n_samples, n_noise_sample, \n",
    "                                              norm, mode, perturbation_constraint, seed, ylabels)()\n",
    "    perturbation_constraint_block = PerturbationConstraintBlock(in_dim, hidden_dim, n_sample, n_noise_sample, \n",
    "                                                                norm, mode, perturbation_constraints, seed)()\n",
    "    \n",
    "    top = pw.stack([in_dim_block, noise_sample_block], margin=0.2, operator='|')\n",
    "    bottom = pw.stack([natural_sample_block, perturbation_constraint_block], margin=0.2, operator='|')\n",
    "    all = pw.stack([top, bottom], margin=0.2, operator='/')\n",
    "\n",
    "    path = os.path.join(root, 'figs', f'decision_maps_{norm}_{mode}.pdf')\n",
    "    all.savefig(path, bbox_inches='tight', pad_inches=0.025)\n",
    "\n",
    "    pw.clear()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L0 / Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 10000\n",
    "in_dims = (100, 500, 1000, 10000)\n",
    "perturbation_constraints_along_with_in_dims = (0.05, 0.05, 0.05, 0.05)\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_samples = (1000, 2000, 5000, 10000)\n",
    "n_noise_sample = 10000\n",
    "n_noise_samples = (1, 10, 100, 10000)\n",
    "norm = 'L0'\n",
    "mode = 'uniform'\n",
    "perturbation_constraint = 0.05\n",
    "perturbation_constraints = (0.0001, 0.0004, 0.001, 0.05)\n",
    "seed = 5\n",
    "\n",
    "all_blocks(\n",
    "    in_dim,\n",
    "    in_dims,\n",
    "    perturbation_constraints_along_with_in_dims,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_samples,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    perturbation_constraints,\n",
    "    seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L0 / Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 10000\n",
    "in_dims = (100, 500, 1000, 10000)\n",
    "perturbation_constraints_along_with_in_dims = (0.05, 0.05, 0.05, 0.05)\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_samples = (1000, 2000, 5000, 10000)\n",
    "n_noise_sample = 10000\n",
    "n_noise_samples = (1, 10, 100, 10000)\n",
    "norm = 'L0'\n",
    "mode = 'gauss'\n",
    "perturbation_constraint = 0.05\n",
    "perturbation_constraints = (0.0001, 0.0004, 0.001, 0.05)\n",
    "seed = 2\n",
    "\n",
    "all_blocks(\n",
    "    in_dim,\n",
    "    in_dims,\n",
    "    perturbation_constraints_along_with_in_dims,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_samples,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    perturbation_constraints,\n",
    "    seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 / Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 10000\n",
    "in_dims = (100, 500, 1000, 10000)\n",
    "perturbation_constraints_along_with_in_dims = (0.078, 0.17, 0.24, 0.78)\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_samples = (1000, 2000, 5000, 10000)\n",
    "n_noise_sample = 10000\n",
    "n_noise_samples = (1, 10, 100, 10000)\n",
    "norm = 'L2'\n",
    "mode = 'uniform'\n",
    "perturbation_constraint = 0.78\n",
    "perturbation_constraints = (0.01, 0.05, 0.1, 0.78)\n",
    "seed = 5\n",
    "\n",
    "all_blocks(\n",
    "    in_dim,\n",
    "    in_dims,\n",
    "    perturbation_constraints_along_with_in_dims,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_samples,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    perturbation_constraints,\n",
    "    seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 / Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 10000\n",
    "in_dims = (100, 500, 1000, 10000)\n",
    "perturbation_constraints_along_with_in_dims = (0.078, 0.17, 0.24, 0.78)\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_samples = (1000, 2000, 5000, 10000)\n",
    "n_noise_sample = 10000\n",
    "n_noise_samples = (1, 10, 100, 10000)\n",
    "norm = 'L2'\n",
    "mode = 'gauss'\n",
    "perturbation_constraint = 0.78\n",
    "perturbation_constraints = (0.01, 0.05, 0.1, 0.78)\n",
    "seed = 2\n",
    "\n",
    "all_blocks(\n",
    "    in_dim,\n",
    "    in_dims,\n",
    "    perturbation_constraints_along_with_in_dims,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_samples,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    perturbation_constraints,\n",
    "    seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linf / Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 10000\n",
    "in_dims = (100, 500, 1000, 10000)\n",
    "perturbation_constraints_along_with_in_dims = (0.03, 0.03, 0.03, 0.03)\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_samples = (1000, 2000, 5000, 10000)\n",
    "n_noise_sample = 10000\n",
    "n_noise_samples = (1, 10, 100, 10000)\n",
    "norm = 'Linf'\n",
    "mode = 'uniform'\n",
    "perturbation_constraint = 0.03\n",
    "perturbation_constraints = (0.001, 0.005, 0.01, 0.03)\n",
    "seed = 5\n",
    "\n",
    "all_blocks(\n",
    "    in_dim,\n",
    "    in_dims,\n",
    "    perturbation_constraints_along_with_in_dims,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_samples,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    perturbation_constraints,\n",
    "    seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linf / Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 10000\n",
    "in_dims = (100, 500, 1000, 10000)\n",
    "perturbation_constraints_along_with_in_dims = (0.03, 0.03, 0.03, 0.03)\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_samples = (1000, 2000, 5000, 10000)\n",
    "n_noise_sample = 10000\n",
    "n_noise_samples = (1, 10, 100, 10000)\n",
    "norm = 'Linf'\n",
    "mode = 'gauss'\n",
    "perturbation_constraint = 0.03\n",
    "perturbation_constraints = (0.001, 0.005, 0.01, 0.03)\n",
    "seed = 2\n",
    "\n",
    "all_blocks(\n",
    "    in_dim,\n",
    "    in_dims,\n",
    "    perturbation_constraints_along_with_in_dims,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_samples,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    perturbation_constraints,\n",
    "    seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure.set_font_scale(1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_blocks(\n",
    "    in_dim: int,\n",
    "    in_dims: Tuple[int, int, int, int],\n",
    "    perturbation_constraints_along_with_in_dims: Tuple[float, float, float, float],\n",
    "    hidden_dim: int,\n",
    "    n_sample: int,\n",
    "    n_noise_sample: int,\n",
    "    n_noise_samples: Tuple[int, int, int, int],\n",
    "    norm: Literal['L2', 'L0'],\n",
    "    mode: Literal['uniform', 'gauss'],\n",
    "    perturbation_constraint: float,\n",
    "    seed: int,\n",
    "):\n",
    "    in_dim_block = InputDimensionBlock(in_dims, hidden_dim, n_sample, n_noise_sample, \n",
    "                                       norm, mode, perturbation_constraints_along_with_in_dims, seed, ylabels)()\n",
    "    noise_sample_block = NoiseSampleBlock(in_dim, hidden_dim, n_sample, n_noise_samples, \n",
    "                                          norm, mode, perturbation_constraint, seed)()\n",
    "    \n",
    "    b = pw.stack([in_dim_block, noise_sample_block], margin=0.2, operator='|')\n",
    "\n",
    "    path = os.path.join(root, 'figs', f'decision_maps_{norm}_{mode}_two.pdf')\n",
    "    b.savefig(path, bbox_inches='tight', pad_inches=0.025)\n",
    "\n",
    "    pw.clear()\n",
    "    Figure.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 10000\n",
    "in_dims = (100, 500, 1000, 10000)\n",
    "perturbation_constraints_along_with_in_dims = (0.078, 0.17, 0.24, 0.78)\n",
    "hidden_dim = 1000\n",
    "n_sample = 1000\n",
    "n_samples = (1000, 2000, 5000, 10000)\n",
    "n_noise_sample = 10000\n",
    "n_noise_samples = (1, 10, 100, 10000)\n",
    "norm = 'L2'\n",
    "mode = 'uniform'\n",
    "perturbation_constraint = 0.78\n",
    "perturbation_constraints = (0.01, 0.05, 0.1, 0.78)\n",
    "seed = 5\n",
    "\n",
    "two_blocks(\n",
    "    in_dim,\n",
    "    in_dims,\n",
    "    perturbation_constraints_along_with_in_dims,\n",
    "    hidden_dim,\n",
    "    n_sample,\n",
    "    n_noise_sample,\n",
    "    n_noise_samples,\n",
    "    norm,\n",
    "    mode,\n",
    "    perturbation_constraint,\n",
    "    seed,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
