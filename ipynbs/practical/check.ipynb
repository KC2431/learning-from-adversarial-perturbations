{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the predictions of normally trained classifiers for adversarial perturbations on natural samples or uniform noises created by `create.py`. Specifically, we assess whether:\n",
    "- The adversarial attacks we implemented work as intended.\n",
    "- The adversarial datasets in each scenario successfully mislead the classifiers.\n",
    "    - Notably, certain adversarial images failed to deceive the classifiers, possibly because of learning bias, architectural bias, or suboptimal PGD optimization.\n",
    "\n",
    "For example, we examined the following values.\n",
    "\n",
    "Dataset: CIFAR10  \n",
    "Scenario: natural_det_L2  \n",
    "Accuracy: [0.98 (1), 0.99 (2), ..., 0.99 (10)]\n",
    "\n",
    "(1) Ratio of truck images (with imperceptible L2 perturbations to mislead the classifier into identifying them as planes) classified as planes by the classifier.  \n",
    "(2) Ratio of plane images (with imperceptible L2 perturbations to mislead the classifier into identifying them as cars) classified as cars by the classifier.  \n",
    "(10) Ratio of ship images (with imperceptible L2 perturbations to mislead the classifier into identifying them as trucks) classified as trucks by the classifier.  \n",
    "\n",
    "Dataset: CIFAR10  \n",
    "Scenario: natural_rand_L2  \n",
    "Accuracy: [0.99 (1), ...]\n",
    "\n",
    "(1) Ratio of images that appear as objects other than planes (with imperceptible L2 perturbations to mislead the classifier into identifying them as planes) classified as planes by the classifier.  \n",
    "\n",
    "These results indicate that L2 perturbations on natural samples can effectively fool the classifier.\n",
    "\n",
    "Dataset: CIFAR10  \n",
    "Scenario: uniform_L2  \n",
    "Accuracy: [0.07 (1), 0.00, 0.00, 1.0 (4), ...]\n",
    "\n",
    "(1) Ratio of noises (with imperceptible L2 perturbations to mislead the classifier into identifying them as planes) classified as planes by the classifier.  \n",
    "(4) Ratio of noises (with imperceptible L2 perturbations to mislead the classifier into identifying them as cats) classified as cats by the classifier.  \n",
    "\n",
    "This suggests that while L2 perturbations on noises can successfully mislead the classifier to identify them as cats, they are less effective in doing so for planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = os.path.join('..', '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils.classifiers import ConvNet, WideResNet\n",
    "from utils.datasets import CIFAR10, FMNIST, MNIST, SequenceDataset\n",
    "from utils.utils import (CalcClassificationAcc, ModelWithNormalization,\n",
    "                         dataloader, freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = [0]\n",
    "dataset_root = os.path.join(os.path.sep, 'root', 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Util:\n",
    "    def __init__(self, dataset_name: Literal['MNIST', 'FMNIST', 'CIFAR10']) -> None:\n",
    "        self.dataset_name = dataset_name\n",
    "        self.classifier = self._define_classifier()\n",
    "        self._load_weight()\n",
    "\n",
    "    def _define_classifier(self) -> ModelWithNormalization:\n",
    "        if self.dataset_name == 'MNIST':\n",
    "            classifier = ConvNet(10)\n",
    "            dataset_cls = MNIST\n",
    "        elif self.dataset_name == 'FMNIST':\n",
    "            classifier = ConvNet(10)\n",
    "            dataset_cls = FMNIST\n",
    "        elif self.dataset_name == 'CIFAR10':\n",
    "            classifier = WideResNet(28, 10, 0.3, 10)\n",
    "            dataset_cls = CIFAR10\n",
    "        else:\n",
    "            raise ValueError(self.dataset_name)\n",
    "        return ModelWithNormalization(classifier, dataset_cls.mean, dataset_cls.std)\n",
    "\n",
    "    def _load_weight(self) -> None:\n",
    "        dir_path = os.path.join(root, 'models', self.dataset_name, 'version_0', 'checkpoints')\n",
    "        ckpt_name = [fname for fname in os.listdir(dir_path) if '.ckpt' in fname][0]\n",
    "        path = os.path.join(dir_path, ckpt_name)\n",
    "\n",
    "        state_dict = torch.load(path, map_location='cpu')['state_dict']\n",
    "        state_dict = OrderedDict((k.replace('classifier.', ''), v) for k, v in state_dict.items())\n",
    "        self.classifier.load_state_dict(state_dict)\n",
    "\n",
    "        freeze(self.classifier)\n",
    "        self.classifier.eval()\n",
    "\n",
    "    def _load_dataset(self, suffix: str) -> SequenceDataset:\n",
    "        p = os.path.join(root, 'datasets', f'{self.dataset_name}_{suffix}', 'dataset')\n",
    "        d = torch.load(p, map_location='cpu')\n",
    "        return SequenceDataset(d['imgs'], d['labels'])\n",
    "    \n",
    "    def test(self, suffix: str) -> None:\n",
    "        print(suffix)\n",
    "\n",
    "        if self.dataset_name in ('MNIST', 'FMNIST'):\n",
    "            batch_size = 60000\n",
    "        elif self.dataset_name == 'CIFAR10':\n",
    "            batch_size = 10000\n",
    "        else:\n",
    "            raise ValueError(self.dataset_name)\n",
    "\n",
    "        d = self._load_dataset(suffix)\n",
    "        loader = dataloader(d, batch_size, False)\n",
    "\n",
    "        acc = CalcClassificationAcc(\n",
    "            accelerator='gpu',\n",
    "            strategy='dp',\n",
    "            devices=device,\n",
    "            precision=16,\n",
    "        ).run(self.classifier, loader, 10, average='none')\n",
    "        print(acc)\n",
    "        print()\n",
    "    \n",
    "    def test_all(self) -> None:\n",
    "        names = [\n",
    "            'natural_rand_L0', \n",
    "            'natural_det_L0',\n",
    "            #'natural_rand_L2', \n",
    "            #'natural_det_L2',\n",
    "            #'natural_rand_Linf', \n",
    "            #'natural_det_Linf',\n",
    "            #'uniform_L0', \n",
    "            #'uniform_L2', \n",
    "            #'uniform_Linf', \n",
    "        ]\n",
    "        for n in names:\n",
    "            self.test(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util('MNIST').test_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util('FMNIST').test_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util('CIFAR10').test_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
